{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2dc0c4a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "91a04155783901da96bbe67b7a5e64bd",
     "grade": false,
     "grade_id": "cell-a336e6ffe0bd52b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Deep Learning Coding Project 2: Image Classification\n",
    "\n",
    "Before we start, please put your **Chinese** name and student ID in following format:\n",
    "\n",
    "Name, 0000000000 // e.g.) 傅炜, 2021123123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a648ddc",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "933b227c504b89bf0c43186e8d0e39a1",
     "grade": true,
     "grade_id": "cell-13ce984a5d4a067a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "刘涵祚,2024011303"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7468705d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cdd86b19ae7e03e9618718ef3c6ea9a0",
     "grade": false,
     "grade_id": "cell-a68075035123f58c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "We will use Python 3, [NumPy](https://numpy.org/), and [PyTorch](https://pytorch.org/) for this coding project. The example code has been tested under the latest stable release version.\n",
    "\n",
    "### Task\n",
    "\n",
    "In this notebook, you need to train a model to classify images. Given an image, you need to distinguish its category,\n",
    "e.g., whether it is a horse or an automobile. There are total 10 classes:\n",
    "airplane, automobile, bird, cat, deer, dog, frog, horse, ship and truck. We\n",
    "release 40,000 images for training, 10,000 images for validation. Each image has\n",
    "a shape of (3, 128, 128). We will evaluate your model in 10,000 images on the test set.\n",
    "\n",
    "Download the dataset from [here](https://cloud.tsinghua.edu.cn/d/00e0704738e04d32978b/) and organize them into a folder named \"cifar_10_4x\".\n",
    "\n",
    "<!-- Images can be classified as \"No Finding\" or **one or more types**. In the basic task, given an image, you only need to tell whether the X-ray indicates \"Infiltration\". In the bonus task, you need to tell whether *each* of the diseases exists.\n",
    "\n",
    "Images are taken from the [ChestX-ray14 dataset](https://www.kaggle.com/nih-chest-xrays/data) and downsampled to (256, 256). We release 44872 gray scale images for training and validation. We will evaluate your model on 10285 images in the test set. The dataset is available [here](https://cloud.tsinghua.edu.cn/d/16d06a89c5b4459db703/) and organized as follows: `train` directory includes all images for training and validation, and each line of `train.txt` records the labels separated by \"|\". -->\n",
    "\n",
    "### Coding\n",
    "\n",
    "We provide a code template. You can add new cells and modify our example to train your own model. To run this code, you should:\n",
    "\n",
    "+ implement your model (named `Net`) in `model.py`.\n",
    "+ implement your training loop in this notebook\n",
    "\n",
    "Your final submitted model should not be larger than **20M**. **Using any pretrained model is NOT permitted**.\n",
    "Besides, before you submit your result, **make sure you can test your model using our evaluation cell.** Name your best model \"cifar10_4x_best.pth\".\n",
    "\n",
    "### Report & Submission\n",
    "\n",
    "Your report should include:\n",
    "\n",
    "1. the details of your model\n",
    "2. all the hyper-parameters\n",
    "3. all the tricks or training techniques you use\n",
    "4. the training curve of your submitted model.\n",
    "\n",
    "Reporting additional ablation studies and how you improve your model are also encouraged.\n",
    "\n",
    "You should submit:\n",
    "\n",
    "+ all codes\n",
    "+ the model checkpoint (only \"cifar10_4x_best.pth\")\n",
    "+ your report (a separate \"pdf\")\n",
    "\n",
    "to web learning. We will use the evaluation code in this notebook to evaluate your model on the test set.\n",
    "\n",
    "### Grading\n",
    "\n",
    "We will grade this coding project based on the performance of your model (70%) and your report (30%). Regarding the evaluation metric of your model, assume your test accuracy is $X$, then your score is\n",
    "\n",
    "$\\frac{min(X,H)−0.6}{H−0.6}×7$\n",
    "\n",
    "where $H$ is accuracy of the model trained by TAs and $H=0.9$, i.e., you will get the full score if your test accuracy is above 90%.\n",
    "\n",
    "**Bonus**: The best submission with the highest testing accuracy will get 1 bonus point for the final course grade.\n",
    "\n",
    "**Avoid plagiarism! Any student who violates academic integrity will be seriously dealt with and receive an F for the course.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f6d8c7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ec5655a0d789db88709122c2a0ce6c9",
     "grade": false,
     "grade_id": "cell-4cee29f989d84cdc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Code Template\n",
    "\n",
    "We have masked the the training loop in this notebook for you to complete. You should also overwrite \"model.py\" and implement your own model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8c2354b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b34bc8b23f9c8e480a9671ef3453e7ac",
     "grade": false,
     "grade_id": "cell-a551fcc5ff27fb87",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b4fcaa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4367d7a728b91da35685f558363c4d66",
     "grade": false,
     "grade_id": "cell-ce69007d45b9103b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Setup Code\n",
    "\n",
    "If you use Colab in this coding project, please uncomment the code, fill the `GOOGLE_DRIVE_PATH_AFTER_MYDRIVE` and run the following cells to mount your Google drive. Then, the notebook can find the required file. If you run the notebook locally, you can skip the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "785a7720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca391e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # TODO: Fill in the Google Drive path where you uploaded the assignment\n",
    "# # Example: If you create a 2022SP folder and put all the files under CP1 folder, then '2022SP/CP1'\n",
    "# # GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = '2022SP/CP1'\n",
    "# GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = None \n",
    "# GOOGLE_DRIVE_PATH = os.path.join('drive', 'MyDrive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n",
    "# print(os.listdir(GOOGLE_DRIVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c62c2445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append(GOOGLE_DRIVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a227e03",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b7e3bc021f202881dd19297b1144711",
     "grade": false,
     "grade_id": "cell-e11eaf041d72deda",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from dataset import CIFAR10_4x\n",
    "from evaluation import evaluation\n",
    "\n",
    "from torchvision.transforms.v2 import MixUp\n",
    "from model_dropout import Net  # this should be implemented by yourself\n",
    "from torch.utils.data import default_collate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01370c88",
   "metadata": {},
   "source": [
    "### Enjoy Your Coding Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ca3c36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    seed = int(seed)\n",
    "    if seed < 0 or seed > (2**32 - 1):\n",
    "        raise ValueError(\"Seed must be between 0 and 2**32 - 1\")\n",
    "    else:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "set_seed(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed366135",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_dir = '.'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([125 / 255, 124 / 255, 115 / 255],\n",
    "                         [60 / 255, 59 / 255, 64 / 255])\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(128, padding=4),\n",
    "    transforms.RandomRotation(30),  # 保持旋转角度不变\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.2),  # 增加颜色抖动的幅度\n",
    "    transforms.RandomGrayscale(p=0.2),  # 增加随机灰度化的概率\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.25, 0.25)),  # 增加随机仿射变换的平移幅度\n",
    "    transforms.RandomPerspective(distortion_scale=0.3, p=0.5),  # 增加随机透视变换的失真比例\n",
    "    # MixUp(alpha=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([125 / 255, 124 / 255, 115 / 255],\n",
    "                         [60 / 255, 59 / 255, 64 / 255]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "228d0018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CIFAR10_4x at .\n",
      "Loading file at .\\cifar_10_4x\\train\n",
      "Loading CIFAR10_4x at .\n",
      "Loading file at .\\cifar_10_4x\\train\n",
      "Loading CIFAR10_4x at .\n",
      "Loading file at .\\cifar_10_4x\\valid\n"
     ]
    }
   ],
   "source": [
    "NUMOFWORKERS = 1\n",
    "trainset = CIFAR10_4x(root=data_root_dir,\n",
    "                      split=\"train\", transform=train_transform)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=64, shuffle=True, num_workers=NUMOFWORKERS, pin_memory=True)\n",
    "simple_trainset = CIFAR10_4x(root=data_root_dir,\n",
    "                             split=\"train\", transform=transform)\n",
    "simple_trainloader = torch.utils.data.DataLoader(\n",
    "    simple_trainset, batch_size=64, shuffle=True, num_workers=NUMOFWORKERS, pin_memory=True)\n",
    "validset = CIFAR10_4x(root=data_root_dir,\n",
    "                      split='valid', transform=transform)\n",
    "validloader = torch.utils.data.DataLoader(\n",
    "    validset, batch_size=128, shuffle=False, num_workers=NUMOFWORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc63d0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of trained parameters: 4740682\n",
      "number of total parameters: 4740682\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "#                                  #\n",
    "#                                  #\n",
    "#                                  #\n",
    "#                                  #\n",
    "#        RUN THIS FOR NEW MODEL    #\n",
    "#                                  #\n",
    "#                                  #\n",
    "#                                  #\n",
    "#                                  #\n",
    "####################################\n",
    "net = Net()\n",
    "print(\"number of trained parameters: %d\" % (\n",
    "    sum([param.nelement() for param in net.parameters() if param.requires_grad])))\n",
    "print(\"number of total parameters: %d\" %\n",
    "      (sum([param.nelement() for param in net.parameters()])))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_history = []\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "print(device)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9e88bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoint_dropout0.1_\\cifar10_4x_best.pth\n",
      "Loaded model from cifar10_4x_best.pth\n"
     ]
    }
   ],
   "source": [
    "# NO EXECUTION\n",
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "wandb.init(project='cifar10_4x_dropout')\n",
    "model_dir = './checkpoint_dropout0.1_'\n",
    "def kaiming_init(m):\n",
    "    if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.kaiming_normal_(m.weight, nonlinearity='tanh')\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "net.apply(kaiming_init)\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "if not os.path.exists(os.path.join(model_dir, 'cifar10_4x_0.pth')):\n",
    "    torch.save(net, os.path.join(model_dir, 'cifar10_4x_0.pth'))\n",
    "\n",
    "# check the model size\n",
    "os.system(' '.join(['du', '-h', os.path.join(model_dir, 'cifar10_4x_0.pth')]))\n",
    "print(os.path.join(model_dir, f'cifar10_4x_best.pth'))\n",
    "if os.path.exists(os.path.join(model_dir, f'cifar10_4x_best.pth')):\n",
    "    net = torch.load(os.path.join(model_dir, f'cifar10_4x_best.pth'), weights_only=False)\n",
    "    print(f\"Loaded model from cifar10_4x_best.pth\")\n",
    "else:\n",
    "    print(f\"Model not found at cifar10_4x_best.pth\")\n",
    "\n",
    "net.to(device)\n",
    "\n",
    "log_path = os.path.join(model_dir, 'log.json')\n",
    "#create the file at log_path\n",
    "log_file = open(log_path, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45e11f0a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9c6c195145fd44d054849497f0be5e3",
     "grade": false,
     "grade_id": "cell-2ea063d5855124d3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def train(epochs:int, optimizer, scheduler, mixup_rate=0.1):\n",
    "    mixup = MixUp(num_classes=10, alpha=mixup_rate)\n",
    "    ##############################################################################\n",
    "    #                  TODO: You need to complete the code here                  #\n",
    "    ##############################################################################\n",
    "    # YOUR CODE HERE\n",
    "    # print(optimizer.param_groups[0])\n",
    "    results = []\n",
    "    best_idx = 0\n",
    "    best_acc = 0\n",
    "    from tqdm import tqdm\n",
    "    from evaluation import evaluation\n",
    "    best_acc = evaluation(net, validloader, device)\n",
    "    print(f'best accuracy: {best_acc:.2f}%')\n",
    "    for epoch in range(epochs):\n",
    "        if epoch > epochs:\n",
    "            break\n",
    "        net.train()\n",
    "        with tqdm(trainloader) as bar:\n",
    "            nums = trues = 0\n",
    "            losses = 0\n",
    "            for i, (xb, yb) in enumerate(bar): #这里 xb是图片 yb是标签\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                # print(xb.shape, yb.shape)\n",
    "                xb, yb = mixup(xb, yb)\n",
    "                # print(xb.shape, yb.shape)\n",
    "                optimizer.zero_grad()\n",
    "                final_output = net(xb)\n",
    "                # print(final_output.shape)\n",
    "                with torch.no_grad():\n",
    "                    # _, answer = final_output.max(dim=1)\n",
    "                    # trues += (answer == yb).sum().item()\n",
    "                    # nums += len(yb)\n",
    "                    # now final_output and yb are mixuped logits, shaped as (batch_size, num_classes)\n",
    "                    trues += (final_output.argmax(dim=1) == yb.argmax(dim=1)).sum().item()\n",
    "                    nums += yb.shape[0] \n",
    "                    # print(f'nums: {nums}, trues: {trues}')\n",
    "                loss = criterion(final_output, yb)\n",
    "                losses += loss\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if (i % 1 == 0):\n",
    "                    train_loss = losses / nums\n",
    "                    bar.set_description(f'Epoch {epoch}/{epochs}, losses:{(losses / nums).sum().item()}, accuracy {100 * trues / nums:.2f}%, learning rate {optimizer.param_groups[0][\"lr\"]}')\n",
    "        train_acc = 100 * trues / nums\n",
    "        print(f'train accuracy: {train_acc:.2f}%')\n",
    "        net.eval()\n",
    "        nums = loss = 0\n",
    "        with tqdm(validloader) as bar:\n",
    "            with torch.no_grad():\n",
    "                for i, (xb, yb) in enumerate(bar):\n",
    "                    xb, yb = xb.to(device), yb.to(device)\n",
    "                    final_output = net(xb)\n",
    "                    loss += criterion(final_output, yb) \n",
    "                    nums += len(yb)\n",
    "        valid_loss = loss / nums\n",
    "        valid_acc = evaluation(net, validloader, device)\n",
    "        print(f'valid loss: {valid_loss:.4f}, valid accuracy: {valid_acc:.2f}%')\n",
    "        results.append({'train accuracy': train_acc, 'valid accuracy': valid_acc, 'loss': (losses / nums).sum().item(), 'valid loss': (valid_loss).sum().item()})\n",
    "        bar.set_description(f'Epoch {epoch}/{epochs}, train accuracy {train_acc:.2f}%, valid accuracy {valid_acc:.2f}%, train loss {losses / nums:.4f}, valid loss {valid_loss:.4f}, learning rate {optimizer.param_groups[0][\"lr\"]}')\n",
    "        #save the checkpoint\n",
    "        scheduler.step()\n",
    "        # torch.save(net, os.path.join(model_dir, f'cifar10_4x_{epoch}.pth'))\n",
    "        if valid_acc > best_acc:\n",
    "            best_acc = valid_acc\n",
    "            best_idx = epoch\n",
    "            torch.save(net, os.path.join(model_dir, f'cifar10_4x_best.pth'))\n",
    "        print(f'best idx: {best_idx}, best accuracy: {best_acc:.2f}%')\n",
    "        with open(log_path, 'w') as f:\n",
    "            f.write(json.dumps(results) + '\\n')\n",
    "        wandb.log({\n",
    "            'epoch': epoch,\n",
    "            'train_loss': train_loss.item(),\n",
    "            'valid_loss': valid_loss.item(),\n",
    "            'train_accuracy': train_acc,\n",
    "            'valid_accuracy': valid_acc,\n",
    "            'learning_rate': optimizer.param_groups[0]['lr']\n",
    "        })\n",
    "    return train_acc, valid_acc\n",
    "    ##############################################################################\n",
    "    #                              END OF YOUR CODE                              #\n",
    "    ##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b81644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def train_simple(epochs:int, optimizer, scheduler):\n",
    "    ##############################################################################\n",
    "    #                  TODO: You need to complete the code here                  #\n",
    "    ##############################################################################\n",
    "    # YOUR CODE HERE\n",
    "    # print(optimizer.param_groups[0])\n",
    "    results = []\n",
    "    best_idx = 0\n",
    "    best_acc = 0\n",
    "    from tqdm import tqdm\n",
    "    from evaluation import evaluation\n",
    "    best_acc = evaluation(net, validloader, device)\n",
    "    print(f'best accuracy: {best_acc:.2f}%')\n",
    "    for epoch in range(epochs):\n",
    "        if epoch > epochs:\n",
    "            break\n",
    "        net.train()\n",
    "        with tqdm(simple_trainloader) as bar:\n",
    "            nums = trues = 0\n",
    "            losses = 0\n",
    "            for i, (xb, yb) in enumerate(bar): #这里 xb是图片 yb是标签\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                # print(xb.shape, yb.shape)\n",
    "                # xb, yb = mixup(xb, yb)\n",
    "                # print(xb.shape, yb.shape)\n",
    "                optimizer.zero_grad()\n",
    "                final_output = net(xb)\n",
    "                # print(final_output.shape)\n",
    "                with torch.no_grad():\n",
    "                    _, answer = final_output.max(dim=1)\n",
    "                    trues += (answer == yb).sum().item()\n",
    "                    nums += len(yb)\n",
    "                    # now final_output and yb are mixuped logits, shaped as (batch_size, num_classes)\n",
    "                    # trues += (final_output.argmax(dim=1) == yb.argmax(dim=1)).sum().item()\n",
    "                    # nums += yb.shape[0] \n",
    "                    # print(f'nums: {nums}, trues: {trues}')\n",
    "                loss = criterion(final_output, yb)\n",
    "                losses += loss\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if (i % 1 == 0):\n",
    "                    train_loss = losses / nums\n",
    "                    bar.set_description(f'Epoch {epoch}/{epochs}, train_loss:{(losses / nums).sum().item()}, accuracy {100 * trues / nums:.2f}%, learning rate {optimizer.param_groups[0][\"lr\"]}')\n",
    "        train_acc = 100 * trues / nums\n",
    "        print(f'train accuracy: {train_acc:.2f}%')\n",
    "        net.eval()\n",
    "        nums = loss = 0\n",
    "        with tqdm(validloader) as bar:\n",
    "            with torch.no_grad():\n",
    "                for i, (xb, yb) in enumerate(bar):\n",
    "                    xb, yb = xb.to(device), yb.to(device)\n",
    "                    final_output = net(xb)\n",
    "                    loss += criterion(final_output, yb) \n",
    "                    nums += len(yb)\n",
    "        valid_loss = loss / nums\n",
    "        valid_acc = evaluation(net, validloader, device)\n",
    "        print(f'valid loss: {valid_loss:.4f}, valid accuracy: {valid_acc:.2f}%')\n",
    "        results.append({'train accuracy': train_acc, 'valid accuracy': valid_acc, 'loss': (losses / nums).sum().item(), 'valid loss': (valid_loss).sum().item()})\n",
    "        bar.set_description(f'Epoch {epoch}/{epochs}, train accuracy {train_acc:.2f}%, valid accuracy {valid_acc:.2f}%, train loss {losses / nums:.4f}, valid loss {valid_loss:.4f}, learning rate {optimizer.param_groups[0][\"lr\"]}')\n",
    "        #save the checkpoint\n",
    "        scheduler.step()\n",
    "        # torch.save(net, os.path.join(model_dir, f'cifar10_4x_{epoch}.pth'))\n",
    "        if valid_acc > best_acc:\n",
    "            best_acc = valid_acc\n",
    "            best_idx = epoch\n",
    "            torch.save(net, os.path.join(model_dir, f'cifar10_4x_best.pth'))\n",
    "        print(f'best idx: {best_idx}, best accuracy: {best_acc:.2f}%')\n",
    "        with open(log_path, 'w') as f:\n",
    "            f.write(json.dumps(results) + '\\n')\n",
    "        wandb.log({\n",
    "            'epoch': epoch,\n",
    "            'train_loss': train_loss.item(),\n",
    "            'valid_loss': valid_loss.item(),\n",
    "            'train_accuracy': train_acc,\n",
    "            'valid_accuracy': valid_acc,\n",
    "            'learning_rate': optimizer.param_groups[0]['lr']\n",
    "        })\n",
    "    return train_acc, valid_acc\n",
    "    ##############################################################################\n",
    "    #                              END OF YOUR CODE                              #\n",
    "    ##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5cf717e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout2d(p=0.15, inplace=False)\n",
      "  )\n",
      "  (1_0): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SiLU()\n",
      "    (3): Dropout2d(p=0.15, inplace=False)\n",
      "    (4): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (1_1): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SiLU()\n",
      "    (3): Dropout2d(p=0.15, inplace=False)\n",
      "    (4): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (1_2): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SiLU()\n",
      "    (3): Dropout2d(p=0.15, inplace=False)\n",
      "    (4): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (2_0): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SiLU()\n",
      "    (3): Dropout2d(p=0.15, inplace=False)\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (2_1): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SiLU()\n",
      "    (3): Dropout2d(p=0.15, inplace=False)\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (2_2): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SiLU()\n",
      "    (3): Dropout2d(p=0.15, inplace=False)\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout2d(p=0.25, inplace=False)\n",
      "  )\n",
      "  (3_0): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SiLU()\n",
      "    (3): Dropout2d(p=0.25, inplace=False)\n",
      "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (3_1): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SiLU()\n",
      "    (3): Dropout2d(p=0.25, inplace=False)\n",
      "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (3_2): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SiLU()\n",
      "    (3): Dropout2d(p=0.25, inplace=False)\n",
      "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (3_3): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SiLU()\n",
      "    (3): Dropout2d(p=0.25, inplace=False)\n",
      "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (3_4): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SiLU()\n",
      "    (3): Dropout2d(p=0.25, inplace=False)\n",
      "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout2d(p=0.25, inplace=False)\n",
      "  )\n",
      "  (4_0): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SiLU()\n",
      "    (3): Dropout2d(p=0.25, inplace=False)\n",
      "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (4_1): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SiLU()\n",
      "    (3): Dropout2d(p=0.25, inplace=False)\n",
      "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (4_2): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SiLU()\n",
      "    (3): Dropout2d(p=0.25, inplace=False)\n",
      "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (4_3): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SiLU()\n",
      "    (3): Dropout2d(p=0.25, inplace=False)\n",
      "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (4_4): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SiLU()\n",
      "    (3): Dropout2d(p=0.25, inplace=False)\n",
      "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout2d(p=0.25, inplace=False)\n",
      "  )\n",
      "  (5_0): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SiLU()\n",
      "    (3): Dropout2d(p=0.15, inplace=False)\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (5_1): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SiLU()\n",
      "    (3): Dropout2d(p=0.15, inplace=False)\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (5_2): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): SiLU()\n",
      "    (3): Dropout2d(p=0.15, inplace=False)\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (final): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): GELU(approximate='none')\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): GELU(approximate='none')\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.enabled = True\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e073ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.to(device)\n",
    "\n",
    "\n",
    "# optimizer = torch.optim.AdamW(net.parameters(),lr=5e-4,weight_decay=2.5e-4) \n",
    "# #at the last epoch, lr becomes 0.1 of the starter lr\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,50, eta_min=5e-5)\n",
    "\n",
    "# print(device)\n",
    "# tacc,vacc = train_simple(50, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d9dd2f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100, losses:0.010815536603331566, accuracy 85.89%, learning rate 3.0628215181561497e-06: 100%|██████████| 625/625 [01:15<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 12.68it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.48%\n",
      "valid loss: 0.0018, valid accuracy: 94.48%\n",
      "best idx: 28, best accuracy: 94.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100, losses:0.01077977754175663, accuracy 85.45%, learning rate 3.125581039058517e-06: 100%|██████████| 625/625 [01:22<00:00,  7.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:09<00:00,  8.45it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.40%\n",
      "valid loss: 0.0016, valid accuracy: 94.40%\n",
      "best idx: 28, best accuracy: 94.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100, losses:0.010954746976494789, accuracy 85.08%, learning rate 3.1882166266369156e-06: 100%|██████████| 625/625 [01:15<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 13.14it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.29%\n",
      "valid loss: 0.0018, valid accuracy: 94.29%\n",
      "best idx: 28, best accuracy: 94.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100, losses:0.010623432695865631, accuracy 86.03%, learning rate 3.2506664671284954e-06: 100%|██████████| 625/625 [01:14<00:00,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 86.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 13.09it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.23%\n",
      "valid loss: 0.0019, valid accuracy: 94.23%\n",
      "best idx: 28, best accuracy: 94.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100, losses:0.01086100097745657, accuracy 85.79%, learning rate 3.3128689300803417e-06: 100%|██████████| 625/625 [01:14<00:00,  8.38it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 13.29it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.36%\n",
      "valid loss: 0.0019, valid accuracy: 94.36%\n",
      "best idx: 28, best accuracy: 94.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100, losses:0.01030739676207304, accuracy 85.92%, learning rate 3.3747626291713295e-06: 100%|██████████| 625/625 [01:15<00:00,  8.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 13.05it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.39%\n",
      "valid loss: 0.0017, valid accuracy: 94.39%\n",
      "best idx: 28, best accuracy: 94.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100, losses:0.010382002219557762, accuracy 86.09%, learning rate 3.4362864827929587e-06: 100%|██████████| 625/625 [01:14<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 86.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 13.35it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.60%\n",
      "valid loss: 0.0019, valid accuracy: 94.60%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100, losses:0.01087257545441389, accuracy 85.28%, learning rate 3.4973797743295833e-06: 100%|██████████| 625/625 [01:15<00:00,  8.33it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 13.16it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.07%\n",
      "valid loss: 0.0018, valid accuracy: 94.07%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100, losses:0.010513143613934517, accuracy 86.06%, learning rate 3.557982212078326e-06: 100%|██████████| 625/625 [01:14<00:00,  8.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 86.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 13.33it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.34%\n",
      "valid loss: 0.0018, valid accuracy: 94.34%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100, losses:0.010635437443852425, accuracy 86.29%, learning rate 3.618033988749763e-06: 100%|██████████| 625/625 [01:14<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 86.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 13.19it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.28%\n",
      "valid loss: 0.0019, valid accuracy: 94.28%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100, losses:0.010090015828609467, accuracy 86.16%, learning rate 3.6774758404904477e-06: 100%|██████████| 625/625 [01:14<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 86.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 13.39it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.19%\n",
      "valid loss: 0.0017, valid accuracy: 94.19%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100, losses:0.010951841250061989, accuracy 85.28%, learning rate 3.736249105369218e-06: 100%|██████████| 625/625 [01:15<00:00,  8.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 13.23it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.26%\n",
      "valid loss: 0.0016, valid accuracy: 94.26%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100, losses:0.010488059371709824, accuracy 86.04%, learning rate 3.7942957812694235e-06: 100%|██████████| 625/625 [04:12<00:00,  2.48it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 86.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 13.13it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.34%\n",
      "valid loss: 0.0019, valid accuracy: 94.34%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100, losses:0.011127795092761517, accuracy 85.21%, learning rate 3.851558583130002e-06: 100%|██████████| 625/625 [01:14<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 13.23it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.25%\n",
      "valid loss: 0.0018, valid accuracy: 94.25%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/100, losses:0.010688195005059242, accuracy 85.78%, learning rate 3.9079809994789504e-06: 100%|██████████| 625/625 [01:14<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 13.21it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.25%\n",
      "valid loss: 0.0019, valid accuracy: 94.25%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/100, losses:0.010328782722353935, accuracy 86.33%, learning rate 3.963507348203281e-06: 100%|██████████| 625/625 [01:14<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 86.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 13.10it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.33%\n",
      "valid loss: 0.0016, valid accuracy: 94.33%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100, losses:0.011051385663449764, accuracy 85.45%, learning rate 4.018082831500594e-06: 100%|██████████| 625/625 [01:14<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 13.18it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.26%\n",
      "valid loss: 0.0019, valid accuracy: 94.26%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/100, losses:0.01087157428264618, accuracy 85.81%, learning rate 4.071653589957839e-06: 100%|██████████| 625/625 [01:14<00:00,  8.42it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 13.10it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.29%\n",
      "valid loss: 0.0017, valid accuracy: 94.29%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100, losses:0.01073393877595663, accuracy 85.53%, learning rate 4.124166755704107e-06: 100%|██████████| 625/625 [01:14<00:00,  8.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 13.20it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.34%\n",
      "valid loss: 0.0021, valid accuracy: 94.34%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100, losses:0.01084999367594719, accuracy 85.36%, learning rate 4.17557050458479e-06: 100%|██████████| 625/625 [01:14<00:00,  8.43it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 13.26it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.32%\n",
      "valid loss: 0.0017, valid accuracy: 94.32%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100, losses:0.010727944783866405, accuracy 86.10%, learning rate 4.225814107305794e-06: 100%|██████████| 625/625 [01:15<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 86.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 13.07it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.12%\n",
      "valid loss: 0.0019, valid accuracy: 94.12%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100, losses:0.010569759644567966, accuracy 85.47%, learning rate 4.2748479794972175e-06: 100%|██████████| 625/625 [01:14<00:00,  8.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 13.30it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.04%\n",
      "valid loss: 0.0017, valid accuracy: 94.04%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/100, losses:0.010697529651224613, accuracy 85.75%, learning rate 4.322623730647139e-06: 100%|██████████| 625/625 [01:14<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 13.17it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.41%\n",
      "valid loss: 0.0016, valid accuracy: 94.41%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/100, losses:0.010976741090416908, accuracy 85.67%, learning rate 4.369094211857214e-06: 100%|██████████| 625/625 [01:13<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 13.14it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.26%\n",
      "valid loss: 0.0021, valid accuracy: 94.26%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/100, losses:0.010477045550942421, accuracy 85.65%, learning rate 4.4142135623729265e-06: 100%|██████████| 625/625 [01:14<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 13.08it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.42%\n",
      "valid loss: 0.0014, valid accuracy: 94.42%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/100, losses:0.010832808911800385, accuracy 85.44%, learning rate 4.4579372548426554e-06: 100%|██████████| 625/625 [01:15<00:00,  8.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 13.31it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.27%\n",
      "valid loss: 0.0016, valid accuracy: 94.27%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/100, losses:0.010787694714963436, accuracy 85.87%, learning rate 4.500222139260746e-06: 100%|██████████| 625/625 [01:14<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 13.16it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.23%\n",
      "valid loss: 0.0018, valid accuracy: 94.23%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/100, losses:0.010588549077510834, accuracy 85.81%, learning rate 4.541026485551406e-06: 100%|██████████| 625/625 [01:14<00:00,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 13.18it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.37%\n",
      "valid loss: 0.0016, valid accuracy: 94.37%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/100, losses:0.009983155876398087, accuracy 86.94%, learning rate 4.580310024751207e-06: 100%|██████████| 625/625 [01:15<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 86.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 13.18it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.40%\n",
      "valid loss: 0.0018, valid accuracy: 94.40%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/100, losses:0.011355257593095303, accuracy 85.22%, learning rate 4.618033988749719e-06: 100%|██████████| 625/625 [01:14<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 13.35it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.23%\n",
      "valid loss: 0.0019, valid accuracy: 94.23%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100, losses:0.010658404789865017, accuracy 85.61%, learning rate 4.654161148548946e-06: 100%|██████████| 625/625 [01:13<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 13.12it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.26%\n",
      "valid loss: 0.0020, valid accuracy: 94.26%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/100, losses:0.010757949203252792, accuracy 85.70%, learning rate 4.688655851003851e-06: 100%|██████████| 625/625 [01:14<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 13.09it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.49%\n",
      "valid loss: 0.0018, valid accuracy: 94.49%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/100, losses:0.010842918418347836, accuracy 85.73%, learning rate 4.721484054007707e-06: 100%|██████████| 625/625 [01:15<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 13.06it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.24%\n",
      "valid loss: 0.0016, valid accuracy: 94.24%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/100, losses:0.011010215617716312, accuracy 85.11%, learning rate 4.752613360087545e-06: 100%|██████████| 625/625 [01:14<00:00,  8.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 13.06it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.29%\n",
      "valid loss: 0.0024, valid accuracy: 94.29%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/100, losses:0.010836394503712654, accuracy 85.74%, learning rate 4.7820130483765544e-06: 100%|██████████| 625/625 [01:14<00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 13.12it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.27%\n",
      "valid loss: 0.0018, valid accuracy: 94.27%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/100, losses:0.010388610884547234, accuracy 86.40%, learning rate 4.809654104931855e-06: 100%|██████████| 625/625 [01:14<00:00,  8.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 86.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 13.29it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.38%\n",
      "valid loss: 0.0017, valid accuracy: 94.38%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/100, losses:0.01037781871855259, accuracy 86.23%, learning rate 4.835509251367778e-06: 100%|██████████| 625/625 [01:14<00:00,  8.38it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 86.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 13.04it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.22%\n",
      "valid loss: 0.0020, valid accuracy: 94.22%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/100, losses:0.010891987010836601, accuracy 85.84%, learning rate 4.859552971776317e-06: 100%|██████████| 625/625 [01:14<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 13.25it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.32%\n",
      "valid loss: 0.0022, valid accuracy: 94.32%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/100, losses:0.01037023775279522, accuracy 86.51%, learning rate 4.881761537908264e-06: 100%|██████████| 625/625 [01:13<00:00,  8.49it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 86.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 13.11it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.34%\n",
      "valid loss: 0.0017, valid accuracy: 94.34%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/100, losses:0.011059993878006935, accuracy 85.40%, learning rate 4.902113032590119e-06: 100%|██████████| 625/625 [01:13<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 13.17it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.23%\n",
      "valid loss: 0.0017, valid accuracy: 94.23%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100, losses:0.010896976105868816, accuracy 85.31%, learning rate 4.920587371353697e-06: 100%|██████████| 625/625 [01:13<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 13.19it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.26%\n",
      "valid loss: 0.0020, valid accuracy: 94.26%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/100, losses:0.010339771397411823, accuracy 86.00%, learning rate 4.937166322257073e-06: 100%|██████████| 625/625 [01:14<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 86.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 13.11it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.26%\n",
      "valid loss: 0.0017, valid accuracy: 94.26%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/100, losses:0.011207020841538906, accuracy 85.30%, learning rate 4.9518335238773045e-06: 100%|██████████| 625/625 [01:13<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 13.18it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.12%\n",
      "valid loss: 0.0018, valid accuracy: 94.12%\n",
      "best idx: 57, best accuracy: 94.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/100, losses:0.0102501530200243, accuracy 86.17%, learning rate 4.9645745014571865e-06: 100%|██████████| 625/625 [01:14<00:00,  8.40it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 86.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 13.16it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.64%\n",
      "valid loss: 0.0015, valid accuracy: 94.64%\n",
      "best idx: 94, best accuracy: 94.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/100, losses:0.010230926796793938, accuracy 86.64%, learning rate 4.975376681190085e-06: 100%|██████████| 625/625 [01:14<00:00,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 86.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 13.15it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.26%\n",
      "valid loss: 0.0017, valid accuracy: 94.26%\n",
      "best idx: 94, best accuracy: 94.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/100, losses:0.01019960455596447, accuracy 86.55%, learning rate 4.984229402628765e-06: 100%|██████████| 625/625 [01:15<00:00,  8.33it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 86.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:06<00:00, 13.14it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.19%\n",
      "valid loss: 0.0017, valid accuracy: 94.19%\n",
      "best idx: 94, best accuracy: 94.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/100, losses:0.010809116996824741, accuracy 85.39%, learning rate 4.991123929205968e-06: 100%|██████████| 625/625 [01:14<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 13.19it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.17%\n",
      "valid loss: 0.0017, valid accuracy: 94.17%\n",
      "best idx: 94, best accuracy: 94.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/100, losses:0.01079593226313591, accuracy 85.28%, learning rate 4.996053456856351e-06: 100%|██████████| 625/625 [01:14<00:00,  8.43it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 13.23it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.46%\n",
      "valid loss: 0.0016, valid accuracy: 94.46%\n",
      "best idx: 94, best accuracy: 94.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/100, losses:0.011147803626954556, accuracy 85.22%, learning rate 4.999013120731271e-06: 100%|██████████| 625/625 [01:14<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:05<00:00, 13.27it/s]\n",
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.21%\n",
      "valid loss: 0.0021, valid accuracy: 94.21%\n",
      "best idx: 94, best accuracy: 94.64%\n",
      "85.225 94.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "net.to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(net.parameters(),lr=5e-6,weight_decay=2.5e-4) \n",
    "#at the last epoch, lr becomes 0.1 of the starter lr\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,100, eta_min=1e-6)\n",
    "\n",
    "print(device)\n",
    "tacc,vacc = train(100, optimizer, scheduler, mixup_rate=0.05)\n",
    "print(tacc, vacc)\n",
    "tacc,vacc = train(100, optimizer, scheduler, mixup_rate=0.1)\n",
    "print(tacc, vacc)\n",
    "tacc,vacc = train(100, optimizer, scheduler, mixup_rate=0.15)\n",
    "print(tacc, vacc)\n",
    "tacc,vacc = train(100, optimizer, scheduler, mixup_rate=0.2)\n",
    "print(tacc, vacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d2897d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "38e39ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the valid images: 94.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "94.35"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluation import evaluation\n",
    "evaluation(net,validloader,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e793356d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "885b0bf12e9c21f035c6df6199532ea9",
     "grade": false,
     "grade_id": "cell-a25d638df48b13bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Before submission, please run the following cell to make sure your model can be correctly graded."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
